{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "name": "",
  "signature": "sha256:78e85aaa33ca0eb637318baf0e30becbc231ce77c84ef090d07cc0e5f3710aa7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Naive Bayes classifier for FASTA data \n",
      "Very simple proof-of-concept in which we use some sequence-specific information to predict affinity for a set of related proteins. \n",
      "\n",
      "Currently we have only 8 sequences for which we have affinity data reported, but this can be expanded easily. \n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To do: \n",
      "    - Run genFasta to download fasta sequences and put into text file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The autoreload extension is already loaded. To reload it, use:\n",
        "  %reload_ext autoreload\n"
       ]
      }
     ],
     "prompt_number": 173
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load fastas, note that first line has a space that shouldn't be there (so need to manually edit for now) "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Bio import SeqIO\n",
      "record_dict = SeqIO.index(\"example.fasta\", \"fasta\")\n",
      "for key in record_dict.iterkeys():\n",
      "    print key\n",
      "    print record_dict[key]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sp|P02625|PRVA_RAT\n",
        "ID: sp|P02625|PRVA_RAT\n",
        "Name: sp|P02625|PRVA_RAT\n",
        "Description: sp|P02625|PRVA_RAT Parvalbumin alpha OS=Rattus norvegicus OX=10116 GN=Pvalb PE=1 SV=2\n",
        "Number of features: 0\n",
        "Seq('MSMTDLLSAEDIKKAIGAFTAADSFDHKKFFQMVGLKKKSADDVKKVFHILDKD...AES', SingleLetterAlphabet())\n",
        "sp|P02618|PRVB_CYPCA\n",
        "ID: sp|P02618|PRVB_CYPCA\n",
        "Name: sp|P02618|PRVB_CYPCA\n",
        "Description: sp|P02618|PRVB_CYPCA Parvalbumin beta OS=Cyprinus carpio OX=7962 PE=1 SV=1\n",
        "Number of features: 0\n",
        "Seq('AFAGVLNDADIAAALEACKAADSFNHKAFFAKVGLTSKSADDVKKAFAIIDQDK...VKA', SingleLetterAlphabet())\n",
        "sp|P02619|PRVB_ESOLU\n",
        "ID: sp|P02619|PRVB_ESOLU\n",
        "Name: sp|P02619|PRVB_ESOLU\n",
        "Description: sp|P02619|PRVB_ESOLU Parvalbumin beta OS=Esox lucius OX=8010 PE=1 SV=1\n",
        "Number of features: 0\n",
        "Seq('SFAGLKDADVAAALAACSAADSFKHKEFFAKVGLASKSLDDVKKAFYVIDQDKS...IKA', SingleLetterAlphabet())\n",
        "sp|P09227|PRVA_CYPCA\n",
        "ID: sp|P09227|PRVA_CYPCA\n",
        "Name: sp|P09227|PRVA_CYPCA\n",
        "Description: sp|P09227|PRVA_CYPCA Parvalbumin alpha OS=Cyprinus carpio OX=7962 PE=1 SV=2\n",
        "Number of features: 0\n",
        "Seq('MAYGGILNDADITAALEACXAXDSFNAKSFFAKVGLSAKTPDDIKKAFAVIDQD...VKA', SingleLetterAlphabet())\n",
        "sp|P02621|PRVB_MERMR\n",
        "ID: sp|P02621|PRVB_MERMR\n",
        "Name: sp|P02621|PRVB_MERMR\n",
        "Description: sp|P02621|PRVB_MERMR Parvalbumin beta OS=Merlangius merlangus OX=8058 PE=1 SV=2\n",
        "Number of features: 0\n",
        "Seq('AFAGILADADCAAAVKACEAADSFSYKAFFAKCGLSGKSADDIKKAFVFIDQDK...VKA', SingleLetterAlphabet())\n",
        "sp|P20472|PRVA_HUMAN\n",
        "ID: sp|P20472|PRVA_HUMAN\n",
        "Name: sp|P20472|PRVA_HUMAN\n",
        "Description: sp|P20472|PRVA_HUMAN Parvalbumin alpha OS=Homo sapiens OX=9606 GN=PVALB PE=1 SV=2\n",
        "Number of features: 0\n",
        "Seq('MSMTDLLNAEDIKKAVGAFSATDSFDHKKFFQMVGLKKKSADDVKKVFHMLDKD...AES', SingleLetterAlphabet())\n",
        "sp|P02628|PRVA_ESOLU\n",
        "ID: sp|P02628|PRVA_ESOLU\n",
        "Name: sp|P02628|PRVA_ESOLU\n",
        "Description: sp|P02628|PRVA_ESOLU Parvalbumin alpha OS=Esox lucius OX=8010 PE=1 SV=1\n",
        "Number of features: 0\n",
        "Seq('AKDLLKADDIKKALDAVKAEGSFNHKKFFALVGLKAMSANDVKKVFKAIDADAS...HEA', SingleLetterAlphabet())\n",
        "sp|Q90YK8|PRVB1_GADCH\n",
        "ID: sp|Q90YK8|PRVB1_GADCH\n",
        "Name: sp|Q90YK8|PRVB1_GADCH\n",
        "Description: sp|Q90YK8|PRVB1_GADCH Parvalbumin beta-1 OS=Gadus chalcogrammus OX=1042646 PE=1 SV=1\n",
        "Number of features: 0\n",
        "Seq('MSFAGVLADADVKAALAGCAAADSFNYKTFFKACGLAAKSHEEVKKAFFVIDQD...VKA', SingleLetterAlphabet())\n"
       ]
      }
     ],
     "prompt_number": 174
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Generate alignment \n",
      "Run from command line"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import Bio.Align.Applications\n",
      "#dir(Bio.Align.Applications)\n",
      "from Bio.Align.Applications import MuscleCommandline\n",
      "cline = MuscleCommandline(input=\"example.fasta\", out=\"example.txt\")\n",
      "print cline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "muscle -in example.fasta -out example.txt\n"
       ]
      }
     ],
     "prompt_number": 175
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "read alignment from running cline above"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Bio import AlignIO\n",
      "align = AlignIO.read(\"example.txt\", \"fasta\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 176
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Manual steps:\n",
      "- calculate a consensus sequence somehow (took from Darin's notebook) \n",
      "- assign affinities from each entry "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "consensus = 'MAFAGLLNDADIAAALEACKAADSFDHKKFFAKVGLKKKSADDVKKAFHIIDQDKSGFIEEDELKLFLQNFSADARALTDAETKAFLKAGDKDGDGKIGVDEFAALVKA-'\n",
      "affinities={\n",
      "  'sp|Q90YK8|PRVB1_GADCH':9.4,\n",
      "  'sp|P02619|PRVB_ESOLU':5.3,\n",
      "  'sp|P02621|PRVB_MERMR':6.9,\n",
      "  'sp|P02618|PRVB_CYPCA':7.3,\n",
      "  'sp|P09227|PRVA_CYPCA':7.1,\n",
      "  'sp|P02628|PRVA_ESOLU':8.8,\n",
      "  'sp|P20472|PRVA_HUMAN':11.6,\n",
      "  'sp|P02625|PRVA_RAT':8.08\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 177
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### My set of classifiers"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def isSame(seq,ref):\n",
      "    x = [seq[i] is ref[i] for i,v in enumerate(seq)]\n",
      "    x = np.asarray(x,dtype=np.int)\n",
      "    quant = np.sum(x)/np.float( np.shape(x)[0] )\n",
      "    #print quant\n",
      "    return quant\n",
      "\n",
      "def isAbove(dictName,key,value=1.):\n",
      "  return np.float( dictName[key]>value)\n",
      "\n",
      "# a.a. charge\n",
      "aaCharge = {\n",
      " 'A':0,'C':0,'D':-1,'E':-1,'F':0,'G':0,'H':0,'I':0,'L':0,'K':1,'M':0,'N':0,'P':0,'Q':0,'R':1,'S':0,'T':0,'V':0,'W':0,'Y':0,\n",
      " '-':0,'X':0\n",
      "}\n",
      "# a.a. charge\n",
      "aaPolar = {\n",
      " 'A':0,'C':0,'D':2,'E':2,'F':0,'G':0,'H':1,'I':0,'L':0,'K':2,'M':1,'N':1,'P':0,'Q':1,'R':2,'S':1,'T':1,'V':0,'W':1,'Y':1,\n",
      " '-':0,'X':0\n",
      "}\n",
      "\n",
      "def totalCharge(seq):\n",
      "  x = [ aaCharge[v] for i,v in enumerate(seq)]     \n",
      "  return np.sum(x,dtype=np.float)  \n",
      "\n",
      "def totalPolar(seq):\n",
      "  x = [ aaPolar[v] for i,v in enumerate(seq)]     \n",
      "  return np.sum(x,dtype=np.float)  \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 179
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Populate with information"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#isSame(align[1].seq,consensus)\n",
      "\n",
      "#dir(align[0])\n",
      "#align[1].seq\n",
      "refAffinity = 8.  # 10**8 \n",
      "for i,daSeq in enumerate(align):\n",
      "  print daSeq.id  \n",
      "    \n",
      "  # traits  \n",
      "  quants = dict()  \n",
      "  quants['isSame']=isSame(daSeq.seq,consensus)\n",
      "  \n",
      "  quants['totalCharge']=totalCharge(daSeq.seq)  \n",
      "    \n",
      "  quants['polar'] = totalPolar(daSeq.seq)    \n",
      "  daSeq.quants = quants\n",
      "    \n",
      "  # observable   \n",
      "  daSeq.classification= isAbove(affinities,daSeq.id,refAffinity)\n",
      "  \n",
      "    #quants[''] =   \n",
      "  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sp|Q90YK8|PRVB1_GADCH\n",
        "sp|P02619|PRVB_ESOLU\n",
        "sp|P02621|PRVB_MERMR\n",
        "sp|P02618|PRVB_CYPCA\n",
        "sp|P09227|PRVA_CYPCA\n",
        "sp|P02628|PRVA_ESOLU\n",
        "sp|P20472|PRVA_HUMAN\n",
        "sp|P02625|PRVA_RAT\n"
       ]
      }
     ],
     "prompt_number": 180
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Create csv file for storage"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "csvData=[]\n",
      "for i,daSeq in enumerate(align):\n",
      "    dictData = daSeq.quants\n",
      "    # get traits\n",
      "    daList = [val for key,val in dictData.iteritems()]\n",
      "    #daString = ''.join(daList)\n",
      "    \n",
      "    # get obserbvable\n",
      "    #daString+=\"%d\"%daSeq.classification\n",
      "    daList.append(daSeq.classification)\n",
      "    #print daList\n",
      "    csvData.append(daList)\n",
      "    \n",
      "import csv\n",
      "fileName = 'seqdata.csv'\n",
      "with open(fileName,mode='w') as csv_file:\n",
      "    daWriter = csv.writer(csv_file,delimiter=',')\n",
      "    for row in csvData:\n",
      "        daWriter.writerow(row)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 181
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 156
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Bayes classication"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np \n",
      "import naive"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 182
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#fileName = 'data.csv'\n",
      "dataset = naive.loadCsv(fileName)\n",
      "\n",
      "print dataset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[75.0, 0.7090909090909091, -9.0, 1.0], [83.0, 0.8090909090909091, -7.0, 0.0], [76.0, 0.7818181818181819, -6.0, 0.0], [84.0, 0.8909090909090909, -6.0, 0.0], [79.0, 0.8363636363636363, -7.0, 0.0], [94.0, 0.6454545454545455, -5.0, 1.0], [101.0, 0.6545454545454545, -5.0, 1.0], [101.0, 0.6545454545454545, -5.0, 1.0]]\n"
       ]
      }
     ],
     "prompt_number": 183
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Analyze data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ar = np.asarray( dataset ) \n",
      "np.shape(ar)\n",
      "\n",
      "#x,y = ar[:,0], ar[:,3]\n",
      "#plt.scatter( x,y,color='r' ) \n",
      "\n",
      "# total charge \n",
      "x,y = ar[:,1], ar[:,3]\n",
      "plt.scatter( x,y ) \n",
      "\n",
      "#x,y = ar[:,2], ar[:,3]\n",
      "#plt.scatter( x,y ) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 184,
       "text": [
        "<matplotlib.collections.PathCollection at 0x7f0c99f3de50>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPdz2llZnnv0AAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f0c9a551290>"
       ]
      }
     ],
     "prompt_number": 184
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Split into training and test set data "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#splitRatio = 0.67\n",
      "splitRatio = 1.\n",
      "\n",
      "trainingSet, testSet = naive.splitDataset(dataset, splitRatio)\n",
      "print('Split {0} rows into train={1} and test={2} rows').format(len(dataset), len(trainingSet), len(testSet))\n",
      "\n",
      "\n",
      "print \"WARNING: we are using our training Set in our testSet \"\n",
      "testSet = trainingSet[0:2]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Split 8 rows into train=8 and test=0 rows\n",
        "WARNING: we are using our training Set in our testSet \n"
       ]
      }
     ],
     "prompt_number": 185
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Prepare model \n",
      "Separate training set into classes. The attributes of each class (e.g.) will be used for computing statistics "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "summaries = naive.summarizeByClass(trainingSet)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 186
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### What's happening in summarizeByClass\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Here we show how on of 'summarizeByClass' routines separates the data in 0 (low aff)  and 1 (high aff) data sets\n",
      "trialSet = trainingSet[0:10]\n",
      "separated = naive.separateByClass(trialSet)\n",
      "print('Separated instances: {0}').format(separated)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Separated instances: {0.0: [[76.0, 0.7818181818181819, -6.0, 0.0], [79.0, 0.8363636363636363, -7.0, 0.0], [84.0, 0.8909090909090909, -6.0, 0.0], [83.0, 0.8090909090909091, -7.0, 0.0]], 1.0: [[75.0, 0.7090909090909091, -9.0, 1.0], [101.0, 0.6545454545454545, -5.0, 1.0], [101.0, 0.6545454545454545, -5.0, 1.0], [94.0, 0.6454545454545455, -5.0, 1.0]]}\n"
       ]
      }
     ],
     "prompt_number": 187
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we compute std dev and mean for each attribute of each class \n",
      "summarizeByClass calls summarize to compute mean/std dev for each attribute\n",
      "<code>\n",
      "def summarize(dataset):\n",
      "\tsummaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
      "\tdel summaries[-1]\n",
      "\treturn summaries\n",
      "</code>\n",
      "\n",
      "Note: each 'event' was reported as a line in the csv file. Each line contained 9 attributes, of which the last column corresponded to output. Hence, in this function we're reporting statistics for each attribute across all events \n",
      "\n",
      "Below I show the mean for each attribute, though we are also computing stddev in the 'real' code"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "summaries = [(np.mean(attribute)) for attribute in zip(*trialSet)]\n",
      "print('Separated instances: {0}').format(summaries)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Separated instances: [86.625, 0.7477272727272728, -6.25, 0.5]\n"
       ]
      }
     ],
     "prompt_number": 188
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Show class statistics. By eyeball it is clear that the attributes associated with each outcome have different means"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "summary = naive.summarizeByClass(trainingSet)\n",
      "\n",
      "print('Summary by class value for outcome=0: {0}').format(summary[0])\n",
      "\n",
      "print('Summary by class value for outcome=1: {0}').format(summary[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Summary by class value for outcome=0: [(80.5, 3.696845502136472), (0.8295454545454545, 0.04657704893617996), (-6.5, 0.5773502691896257)]\n",
        "Summary by class value for outcome=1: [(92.75, 12.284814474246922), (0.665909090909091, 0.029105110170149308), (-6.0, 2.0)]\n"
       ]
      }
     ],
     "prompt_number": 189
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Compute probabilites of belonging to a given class\n",
      "\n",
      "First, we'll compute $P(\\theta|D)$ for a single attribute, assuming Gaussian statistics. Here, the mean value we pass in is our 'D', and our 'theta' is essentially a measure of whether we belong to a given class."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean = 73\n",
      "stdev = 6.2\n",
      "\n",
      "x = 100\n",
      "probability = naive.calculateProbability(x, mean, stdev)\n",
      "print('Probability of belonging to this class: {0}').format(probability)\n",
      "\n",
      "x = 75\n",
      "probability = naive.calculateProbability(x, mean, stdev)\n",
      "print('Probability of belonging to this class: {0}').format(probability)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Probability of belonging to this class: 4.90233998485e-06\n",
        "Probability of belonging to this class: 0.0610832884561\n"
       ]
      }
     ],
     "prompt_number": 190
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since we have multiple attributes that are assumed independent, our probability of theta belonging to a given class is based on the product of all attribute probabilities in a given event \n",
      "\n",
      "<code>\n",
      "def calculateClassProbabilities(summaries, inputVector):\n",
      "\tprobabilities = {}\n",
      "\tfor classValue, classSummaries in summaries.iteritems():\n",
      "\t\tprobabilities[classValue] = 1\n",
      "\t\tfor i in range(len(classSummaries)):\n",
      "\t\t\tmean, stdev = classSummaries[i]\n",
      "\t\t\tx = inputVector[i]\n",
      "\t\t\tprobabilities[classValue] *= calculateProbability(x, mean, stdev)\n",
      "\treturn probabilities\n",
      "</code>    \n",
      "\n",
      "\n",
      "Ex. here we create a 'classSummary' set, each with one attribute for which means (1 or 20) and stddevs (0.5 or 5.0) are reported. We ask for the probability of belonging to each class, given that the mean in (our inputvector) is 1.1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if 0: \n",
      "    summaries = {0:[(1, 0.5)], 1:[(20, 5.0)]}\n",
      "    inputVector = [1.1, '?']\n",
      "    probabilities = naive.calculateClassProbabilities(summaries, inputVector)\n",
      "    print('Probabilities for each class: {0}').format(probabilities)\n",
      "    print(\"My class is {0}\").format( naive.predict(summaries,inputVector))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 193
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll run the classifier on a subset of the test set "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# prepare model\n",
      "summaries = naive.summarizeByClass(trainingSet)\n",
      "# test model\n",
      "subset = testSet[0:2]\n",
      "print \"Subset\", subset\n",
      "predictions = naive.getPredictions(summaries, subset)\n",
      "print \"Predictions\", predictions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Subset [[75.0, 0.7090909090909091, -9.0, 1.0], [101.0, 0.6545454545454545, -5.0, 1.0]]\n",
        "Predictions [1.0, 1.0]\n"
       ]
      }
     ],
     "prompt_number": 194
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## <font color=red>Don't do for now, since we don't have a bunch of data to work with </font>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Execute all steps. \n",
      "We also have a metric that allows us to test the classifier performance based our test data set "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "naive.main()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Split 768 rows into train=514 and test=254 rows\n",
        "Accuracy: 72.0472440945%\n"
       ]
      }
     ],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}